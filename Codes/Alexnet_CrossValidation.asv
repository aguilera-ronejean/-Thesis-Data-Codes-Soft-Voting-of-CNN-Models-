outputFolder = fullfile('../','tympanic_membrane_dataset_jittered/');
rootFolder = fullfile(outputFolder, 'dataset');
categories = {'earwax', 'csom', 'aom', 'normal_img'};
imds = imageDatastore(fullfile(rootFolder,categories),'LabelSource','foldernames');

% Balance the Datasets 
tbl = countEachLabel(imds);
minSetCount = min(tbl{:,2})
imds = splitEachLabel(imds,minSetCount, 'randomized');

% Determine the split up
total_split=countEachLabel(imds)
% Number of Images
num_images=length(imds.Labels);

%%K-fold Validation
% Number of folds
num_folds=5;

% Loop for each fold
for fold_idx=1:num_folds
    
    fprintf('Processing %d among %d folds \n',fold_idx,num_folds);
    
   % Test Indices for current fold
    test_idx=fold_idx:num_folds:num_images;

    % Test cases for current fold
    imdsTest = subset(imds,test_idx);
     labeltest=countEachLabel(imdsTest)
    % Train indices for current fold
    train_idx=setdiff(1:length(imds.Files),test_idx);
    
    % Train cases for current fold
    imdsTrain = subset(imds,train_idx);
 labeltrain= countEachLabel(imdsTrain)
    % alexNet Architecture 
    net=alexnet;
     % Replacing the last layers with new layers
    layersTransfer = net.Layers(1:end-7);%81.1 7 %-3 75%
    clear net;
 % Number of categories
    numClasses = 4; %set number of categories
layers = [
    layersTransfer
    fullyConnectedLayer(4)
    softmaxLayer
    classificationLayer];

   
    %rmsprop,sgdm,adam
    % Training Options, we choose a small mini-batch size due to limited images 
    options = trainingOptions( ...
        'sgdm',...
        'ExecutionEnvironment','auto',...
        'MaxEpochs',32, ...
        'MiniBatchSize',24,...
        'Shuffle','every-epoch', ...
        'InitialLearnRate',0.0003, ...
        'LearnRateSchedule','piecewise', ...
        'LearnRateDropFactor',0.1, ...
        'LearnRateDropPeriod',16, ...
        'Verbose',false, ...
        'Plots','training-progress');
    
    % Data Augumentation %97.3 without shear
    augmenter = imageDataAugmenter( ...
        'RandXReflection',1,...
        'RandXShear',[-0.05 0.05], ...
        'RandYShear',[-0.05 0.05]);
    
   % Resizing all training images to [227 227] for Alexnet architecture
    auimds = augmentedImageDatastore([227 227],imdsTrain,'DataAugmentation',augmenter);
    
    % Training
    netTransfer = trainNetwork(auimds,layers,options);
    
    % Resizing all testing images to [227 227] for Alexnet architecture   
     augtestimds = augmentedImageDatastore([227 227],imdsTest);
   
    % Testing and their corresponding Labels and Posterior for each Case
    [predicted_labels(test_idx),posterior(test_idx,:)] = classify(netTransfer, augtestimds);
    % Save the Independent ResNet Architectures obtained for each Fold
    save(sprintf('ALEXNETcustom6_%d_among_%d_folds',fold_idx,num_folds),'netTransfer','test_idx','train_idx','labeltest','labeltrain');
    
    % Clearing unnecessary variables 
    clearvars -except fold_idx num_folds num_images predicted_labels posterior imds netTransfer;
    
end
analyzeNetwork(netTransfer)
%%Performance Study
% Actual Labels
actual_labels=imds.Labels;

% Confusion Matrix
figure;
plotconfusion(actual_labels,predicted_labels')
title('Confusion Matrix: alexnet');
%ROC CURVE
test_labels=double(nominal(imds.Labels));

% ROC Curve - Our target class is the first class in this scenario 
[fp_rate,tp_rate,T,AUC]=perfcurve(test_labels,posterior(:,1),1);
figure;
plot(fp_rate,tp_rate,'b-');
grid on;
xlabel('False Positive Rate');
ylabel('Detection Rate');
% Area under the ROC curve value
AUC()
%evaluation
%Evaluate(YValidation,YPred)
ACTUAL=actual_labels;
PREDICTED=predicted_labels';
idx = (ACTUAL()=='NORMAL');
%disp(idx)
p = length(ACTUAL(idx));
n = length(ACTUAL(~idx));
N = p+n;
tp = sum(ACTUAL(idx)==PREDICTED(idx));
tn = sum(ACTUAL(~idx)==PREDICTED(~idx));
fp = n-tn;
fn = p-tp;

tp_rate = tp/p;
tn_rate = tn/n;

accuracy = (tp+tn)/N;
sensitivity = tp_rate;
specificity = tn_rate;
precision = tp/(tp+fp);
recall = sensitivity;
f_measure = 2*((precision*recall)/(precision + recall));
gmean = sqrt(tp_rate*tn_rate);

disp(['accuracy=' num2str(accuracy)])
disp(['sensitivity=' num2str(sensitivity)])
disp(['specificity=' num2str(specificity)])
disp(['precision=' num2str(precision)])
disp(['recall=' num2str(recall)])
disp(['f_measure=' num2str(f_measure)])
disp(['gmean=' num2str(gmean)])
title={'''AUC_','''accuracy','''sensitivity','''specificity','''precision','''recall','''f_measure','''gmean'};
VALUES=[AUC,accuracy,sensitivity,specificity,precision,recall,f_measure,gmean];
filename='performance.xlsx';
writecell(filename,title,'Sheet1','A1')
writecell(filename,VALUES,'Sheet1')
%winopen(filename);  
%end
winopen(filename);